---
title: "Dunhumby EDA"
subtitle: "From"
editor: visual
date:  2 Mar 2023
date-modified: "`r Sys.Date()`"
code-copy: true
execute: 
  echo: true
  eval: true
  warning: false
  error: false
website: 
    google-analytics: "G-PKMQ2W4ZRC"
format:
  html:
    code-overflow: wrap
    code-fold: true
    code-summary: "Show the code"
    css: styles.css
---

# **1. R PACKAGE REQUIRED**

The following are the packages required for this exercise :

## **1.1 Load R Packages**

```{r}
pacman::p_load(readxl, ggHoriPlot, ggthemes, ggpubr, ggiraph, lubridate, tidyverse, data.table, plotly, viridis, hrbrthemes, CGPfunctions, ggrepel, corrplot, corrr)
```

# **2. DATA PROCESSING & PREPARATION**

## **2.1 Import Data**

### 2.1.1 campaign_desc

```{r}
campaign_desc <- read_csv("data2/campaign_desc.csv")

glimpse(campaign_desc, 70)
```

Remarks :

This table gives the length of time for which a campaign runs.

So, any coupons received as part of a campaign are valid within the dates contained in this table.

### 2.1.2 campaign_table

```{r}
campaign_table <- read_csv("data2/campaign_table.csv")

glimpse(campaign_table, 70)
```

Remarks :

This table lists the campaigns received by each household in the study.

Each household received a different set of campaigns.

### 2.1.3 causal_data

The file is too large to push over to Github. So, I have to split the datasets to keep each dataset less than 100 MB.

```{r}
#| output: false
#| eval: false
causal_1 <- read_csv("data2/causal_data.csv") %>%
  select(-STORE_ID) %>%
  slice(1:3000000)

write_rds(causal_1,
          "data2/causal_1.rds")

causal_2 <- read_csv("data2/causal_data.csv") %>%
  select(-STORE_ID) %>%
  slice(3000001:6000000)

write_rds(causal_2,
          "data2/causal_2.rds")
```

```{r}
#| output: false
#| eval: false
causal_3 <- read_csv("data2/causal_data.csv") %>%
  select(-STORE_ID) %>%
  slice(6000001:9000000)

write_rds(causal_3,
          "data2/causal_3.rds")
```

```{r}
#| output: false
#| eval: false
causal_4 <- read_csv("data2/causal_data.csv") %>%
  select(-STORE_ID) %>%
  slice(9000001:12000000)

write_rds(causal_4,
          "data2/causal_4.rds")
```

```{r}
#| output: false
#| eval: false
causal_5 <- read_csv("data2/causal_data.csv") %>%
  select(-STORE_ID) %>%
  slice(12000001:15000000)

write_rds(causal_5,
          "data2/causal_5.rds")
```

```{r}
#| output: false
#| eval: false
causal_6 <- read_csv("data2/causal_data.csv") %>%
  select(-STORE_ID) %>%
  slice(15000001:18000000)

write_rds(causal_6,
          "data2/causal_6.rds")
```

```{r}
#| output: false
#| eval: false
causal_7 <- read_csv("data2/causal_data.csv") %>%
  select(-STORE_ID) %>%
  slice(18000001:21000000)

write_rds(causal_7,
          "data2/causal_7.rds")
```

```{r}
#| output: false
#| eval: false
causal_8 <- read_csv("data2/causal_data.csv") %>%
  select(-STORE_ID) %>%
  slice(21000001:24000000)

write_rds(causal_8,
          "data2/causal_8.rds")
```

```{r}
#| output: false
#| eval: false
causal_9 <- read_csv("data2/causal_data.csv") %>%
  select(-STORE_ID) %>%
  slice(24000001:27000000)

write_rds(causal_9,
          "data2/causal_9.rds")
```

```{r}
#| output: false
#| eval: false
causal_10 <- read_csv("data2/causal_data.csv") %>%
  select(-STORE_ID) %>%
  slice(27000001:30000000)

write_rds(causal_10,
          "data2/causal_10.rds")
```

```{r}
#| output: false
#| eval: false
causal_11 <- read_csv("data2/causal_data.csv") %>%
  select(-STORE_ID) %>%
  slice(30000001:33000000)

write_rds(causal_11,
          "data2/causal_11.rds")
```

```{r}
#| output: false
#| eval: false
causal_12 <- read_csv("data2/causal_data.csv") %>%
  select(-STORE_ID) %>%
  slice(33000001:36000000)

write_rds(causal_12,
          "data2/causal_12.rds")
```

```{r}
#| output: false
#| eval: false
causal_13 <- read_csv("data2/causal_data.csv") %>%
  select(-STORE_ID) %>%
  slice(36000001:36786524)

write_rds(causal_13,
          "data2/causal_13.rds")
```

```{r}
causal_1 <- read_rds("data2/causal_1.rds")
causal_2 <- read_rds("data2/causal_2.rds")
causal_3 <- read_rds("data2/causal_3.rds")
causal_4 <- read_rds("data2/causal_4.rds")
causal_5 <- read_rds("data2/causal_5.rds")
causal_6 <- read_rds("data2/causal_6.rds")
causal_7 <- read_rds("data2/causal_7.rds")
causal_8 <- read_rds("data2/causal_8.rds")
causal_9 <- read_rds("data2/causal_9.rds")
causal_10 <- read_rds("data2/causal_10.rds")
causal_11 <- read_rds("data2/causal_11.rds")
causal_12 <- read_rds("data2/causal_12.rds")
causal_13 <- read_rds("data2/causal_13.rds")
```

Remarks :

This table signifies whether a given product was featured in the weekly mailer or was part of an in-store display (other than regular product placement).

### 2.1.4 coupon

```{r}
coupon <- read_csv("data2/coupon.csv")

glimpse(coupon, 70)
```

Remarks :

This table lists all the coupons sent to customers as part of a campaign, as well as the products for which each coupon is redeemable.

-   Some coupons are redeemable for multiple products.

    -   One example is a coupon for any private label frozen vegetable. There are a large number of products where this coupon could be redeemed.

-   For campaign Type A, this table provides the pool of possible coupons. Each customer participating in a TypeA campaign received 16 coupons out of the pool. The 16 coupons were selected based on the customer's prior purchase behavior. Identifying the specific 16 coupons that each customer received is outside the scope of this database.

-   For campaign TypeB and TypeC, all customers participating in a campaign receives all coupons pertaining to that campaign.

### 2.1.5 coupon_redempt

```{r}
coupon_redempt <- read_csv("data2/coupon_redempt.csv")

glimpse(coupon_redempt, 70)
```

Remarks :

This table identifies the coupons that each household redeemed.

### 2.1.6 hh_demographic

```{r}
demographic <- read_csv("data2/hh_demographic.csv")

glimpse(demographic, 70)
```

```{r}
questionr::freq(duplicated(demographic$household_key))
```

Remarks :

-   No duplication in household_key.

-   Only 801 households demographic data available.

```{r}
unique(demographic$AGE_DESC)
```

```{r}
unique(demographic$MARITAL_STATUS_CODE)
```

### 2.1.7 product

```{r}
product <- read_csv("data2/product.csv")

glimpse(product, 70)
```

Remarks :

This table contains information on each product sold such as type of product, national or private label and a brand identifier.

!!!!! Which Manufacturers to source for supplies that give highest profit after drive by campaign.

### 2.1.8 transaction_data

```{r}
#| output: false
#| eval: false
transaction_1 <- read_csv("data2/transaction_data.csv") %>%
  select(-STORE_ID) %>%
  slice(1:1000000)

write_rds(transaction_1,
          "data2/transaction_1.rds")
```

```{r}
#| output: false
#| eval: false
transaction_2 <- read_csv("data2/transaction_data.csv") %>%
  select(-STORE_ID) %>%
  slice(1000001:2000000)

write_rds(transaction_2,
          "data2/transaction_2.rds")
```

```{r}
#| output: false
#| eval: false
transaction_3 <- read_csv("data2/transaction_data.csv") %>%
  select(-STORE_ID) %>%
  slice(2000001:2595732)

write_rds(transaction_3,
          "data2/transaction_3.rds")
```

```{r}
transaction_1 <- read_rds("data2/transaction_1.rds")
transaction_2 <- read_rds("data2/transaction_2.rds")
transaction_3 <- read_rds("data2/transaction_3.rds")
```

# 3. DATA PREP

## 3.1 Group transaction data by household_key

```{r}
trans_1 <- transaction_1 %>%
  group_by(household_key) %>%
  summarise(totalSales = sum(SALES_VALUE), 
            totalDisc = sum(RETAIL_DISC)) %>%
  mutate(sales = totalSales + totalDisc)

trans_2 <- transaction_2 %>%
  group_by(household_key) %>%
  summarise(totalSales = sum(SALES_VALUE), 
            totalDisc = sum(RETAIL_DISC)) %>%
  mutate(sales = totalSales + totalDisc)

trans_3 <- transaction_3 %>%
  group_by(household_key) %>%
  summarise(totalSales = sum(SALES_VALUE), 
            totalDisc = sum(RETAIL_DISC)) %>%
  mutate(sales = totalSales + totalDisc)

trans <- merge(trans_1, trans_2, all = TRUE)
trans1 <- merge(trans, trans_3, all = TRUE)
```

Remarks :

Only 801 households demographic data available.

```{r}
trans1.1 <- trans1 %>%
  group_by(household_key) %>%
  summarise(totalSales1 = sum(totalSales), 
            totalDisc1 = sum(totalDisc)) %>%
  mutate(sales1 = totalSales1 + totalDisc1)
```

## 3.2 Merge Tables

### 3.2.1 demographic & trans1.1

```{r}
demogTrans <- demographic %>%
  full_join(trans1.1)
```

### 3.2.2 campaign_table & campaign_desc

```{r}
campaigns <- campaign_table %>%
  full_join(campaign_desc)
```

```{r}
campaigns_1 <- campaigns %>%
  left_join(coupon_redempt) %>%
  drop_na(COUPON_UPC) %>% 
  mutate(day_response = (DAY - START_DAY)+1) %>%
  mutate(duration = (END_DAY - START_DAY)+1)
```

```{r}
#| output: false
#| eval: false
campaigns_hh <- campaigns_1 %>%
  plyr::join_all(list(transaction_1, transaction_2, transaction_3), 
                 by = c(`DAY`, `household_key`), 
                 type = "left")
```

# 4. CORRELATION ANALYSIS

## 4.1 Set household_key as the row id

```{r}
cluster_vars <- column_to_rownames(demogTrans,
                                   var = 'household_key')
```

```{r}
#| eval: false
#| output: false
cluster_vars %>%
  select(sales, AGE_DESC, MARITAL_STATUS_CODE, HOUSEHOLD_SIZE_DESC) %>%
  correlate()
```

Build Regression Model

```{r}
model_test <- lm(sales1 ~ AGE_DESC + HOMEOWNER_DESC + HOUSEHOLD_SIZE_DESC,
                 data = cluster_vars)

summary(model_test)
```

```{r}
#| eval: false
#| output: false
cluster_vars <- 
wp_stdMM <- normalize(cluster_varsNF1)
```
